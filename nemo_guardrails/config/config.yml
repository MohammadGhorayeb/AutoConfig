models:
  - type: main
    engine: custom
    model: custom_llama

rails:
  input:
    flows:
      - self check input

  output:
    flows:
      - self check output

prompts:
  - task: self_check_input
    content: |
      <instructions>
      You are a helpful AI assistant. Your task is to check if the user's input is appropriate.
      If the input contains harmful, illegal, unethical,offensive or sex content, respond with "UNSAFE".
      Otherwise, respond with "SAFE".
      </instructions>

      User input: "{{ user_input }}"
      Is this input safe?

  - task: self_check_output
    content: |
      <instructions>
      You are a helpful AI assistant. Your task is to check if the response is appropriate.
      If the response contains harmful, illegal, unethical, offensive or sex content, respond with "UNSAFE".
      Otherwise, respond with "SAFE".
      </instructions>

      Response: "{{ bot_response }}"
      Is this response safe?