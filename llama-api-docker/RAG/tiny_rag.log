2025-04-21 12:04:40,896 - INFO - Available memory: 26522.48 MB
2025-04-21 12:04:40,896 - INFO - Using chunk_size=256 and batch_size=3
2025-04-21 12:04:40,897 - INFO - Found 3 documents
2025-04-21 12:04:40,897 - INFO - Processing document ai_systems.txt
2025-04-21 12:04:40,897 - INFO - Processing document: ai_systems.txt
2025-04-21 12:04:40,897 - INFO - Document ai_systems.txt split into 20 chunks
2025-04-21 12:04:40,898 - INFO - Document processed: 20 chunks created
2025-04-21 12:04:40,989 - INFO - Processing document employee_info.txt
2025-04-21 12:04:40,989 - INFO - Processing document: employee_info.txt
2025-04-21 12:04:40,990 - INFO - Document employee_info.txt split into 17 chunks
2025-04-21 12:04:40,990 - INFO - Document processed: 17 chunks created
2025-04-21 12:04:41,076 - INFO - Processing document sample_document.txt
2025-04-21 12:04:41,076 - INFO - Processing document: sample_document.txt
2025-04-21 12:04:41,076 - INFO - Document sample_document.txt split into 26 chunks
2025-04-21 12:04:41,076 - INFO - Document processed: 26 chunks created
2025-04-21 12:04:41,161 - INFO - Loading embedding model (all-MiniLM-L6-v2) with cache dir: C:\Users\TechTroniX\Documents\AutoConfig-1\llama-api-docker\RAG\model_cache
2025-04-21 12:04:41,163 - INFO - Use pytorch device_name: cpu
2025-04-21 12:04:41,163 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-04-21 12:04:44,017 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-04-21 12:07:07,196 - INFO - Embedding model loaded successfully
2025-04-21 12:07:07,196 - INFO - Creating embeddings for 63 chunks in batches of 3
2025-04-21 12:07:07,196 - INFO - Processing batch 1/21
2025-04-21 12:07:07,294 - INFO - Batch 1 processed
2025-04-21 12:07:07,395 - INFO - Processing batch 2/21
2025-04-21 12:07:07,414 - INFO - Batch 2 processed
2025-04-21 12:07:07,512 - INFO - Processing batch 3/21
2025-04-21 12:07:07,530 - INFO - Batch 3 processed
2025-04-21 12:07:07,627 - INFO - Processing batch 4/21
2025-04-21 12:07:07,653 - INFO - Batch 4 processed
2025-04-21 12:07:07,749 - INFO - Processing batch 5/21
2025-04-21 12:07:07,766 - INFO - Batch 5 processed
2025-04-21 12:07:07,864 - INFO - Processing batch 6/21
2025-04-21 12:07:07,882 - INFO - Batch 6 processed
2025-04-21 12:07:07,971 - INFO - Processing batch 7/21
2025-04-21 12:07:07,988 - INFO - Batch 7 processed
2025-04-21 12:07:08,083 - INFO - Processing batch 8/21
2025-04-21 12:07:08,102 - INFO - Batch 8 processed
2025-04-21 12:07:08,194 - INFO - Processing batch 9/21
2025-04-21 12:07:08,210 - INFO - Batch 9 processed
2025-04-21 12:07:08,310 - INFO - Processing batch 10/21
2025-04-21 12:07:08,329 - INFO - Batch 10 processed
2025-04-21 12:07:08,420 - INFO - Processing batch 11/21
2025-04-21 12:07:08,438 - INFO - Batch 11 processed
2025-04-21 12:07:08,528 - INFO - Processing batch 12/21
2025-04-21 12:07:08,548 - INFO - Batch 12 processed
2025-04-21 12:07:08,641 - INFO - Processing batch 13/21
2025-04-21 12:07:08,657 - INFO - Batch 13 processed
2025-04-21 12:07:08,755 - INFO - Processing batch 14/21
2025-04-21 12:07:08,774 - INFO - Batch 14 processed
2025-04-21 12:07:08,870 - INFO - Processing batch 15/21
2025-04-21 12:07:08,890 - INFO - Batch 15 processed
2025-04-21 12:07:08,986 - INFO - Processing batch 16/21
2025-04-21 12:07:09,004 - INFO - Batch 16 processed
2025-04-21 12:07:09,105 - INFO - Processing batch 17/21
2025-04-21 12:07:09,125 - INFO - Batch 17 processed
2025-04-21 12:07:09,224 - INFO - Processing batch 18/21
2025-04-21 12:07:09,243 - INFO - Batch 18 processed
2025-04-21 12:07:09,335 - INFO - Processing batch 19/21
2025-04-21 12:07:09,354 - INFO - Batch 19 processed
2025-04-21 12:07:09,449 - INFO - Processing batch 20/21
2025-04-21 12:07:09,467 - INFO - Batch 20 processed
2025-04-21 12:07:09,571 - INFO - Processing batch 21/21
2025-04-21 12:07:09,588 - INFO - Batch 21 processed
2025-04-21 12:07:09,679 - INFO - Combining all embeddings
2025-04-21 12:07:09,680 - INFO - Saving embeddings to C:\Users\TechTroniX\Documents\AutoConfig-1\llama-api-docker\RAG\embeddings\chunk_embeddings.npy
2025-04-21 12:07:09,682 - INFO - Index data saved to C:\Users\TechTroniX\Documents\AutoConfig-1\llama-api-docker\RAG\embeddings\rag_index.json
2025-04-21 12:07:09,682 - INFO - RAG index created successfully with 63 chunks from 3 documents
